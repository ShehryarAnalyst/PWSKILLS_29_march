{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de584713",
   "metadata": {},
   "source": [
    "## Assignments Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c695f",
   "metadata": {},
   "source": [
    "__Q1. What is Lasso Regression, and how does it differ from other regression techniques?__\n",
    "\n",
    "__Ans)__ Lasso Regression is a regression technique that combines ordinary least squares regression with a penalty term to encourage sparsity in coefficient estimates. It differs from other regression techniques by performing automatic variable selection, producing sparse solutions, using L1 regularization, reducing coefficient magnitudes, and providing an interpretable model. Lasso Regression is particularly useful in high-dimensional data or when identifying the most important predictors is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c79bd",
   "metadata": {},
   "source": [
    "__Q2. What is the main advantage of using Lasso Regression in feature selection?__\n",
    "\n",
    "__Ans)__ The main advantage of using Lasso Regression for feature selection is its ability to automatically identify and select the most relevant predictors in the model. By introducing a penalty term that drives some coefficients to exactly zero, Lasso Regression can effectively exclude irrelevant or less important predictors from the model. This sparsity-inducing property allows for a more interpretable model and reduces the risk of overfitting by focusing on the most influential predictors. Using Lasso Regression for feature selection can simplify the model, improve model interpretability, and potentially enhance prediction performance by eliminating unnecessary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4766d2e",
   "metadata": {},
   "source": [
    "__Q3. How do you interpret the coefficients of a Lasso Regression model?__\n",
    "\n",
    "__Ans)__ Interpreting the coefficients of a Lasso Regression model involves considering the non-zero coefficients as they represent the selected predictors with significant impacts on the target variable. The magnitude and sign of these coefficients indicate the strength and direction of the relationships. Coefficients that are exactly zero indicate the exclusion of certain predictors from the model. Comparing the magnitudes of the non-zero coefficients provides insights into the relative importance of the predictors. Proper scaling of the predictor variables is important for accurate coefficient interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04166f",
   "metadata": {},
   "source": [
    "__Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?__\n",
    "\n",
    "__Ans)__ In Lasso Regression, the tuning parameter is the regularization parameter (lambda or alpha). It controls the amount of penalty applied to the coefficient estimates. A higher value of the regularization parameter increases sparsity by pushing more coefficients towards zero, resulting in a model with fewer predictors. Conversely, a lower value reduces sparsity and allows more coefficients to remain non-zero. The choice of the regularization parameter affects the trade-off between model complexity and performance, and it is typically determined using techniques like cross-validation or information criteria. The optimal value balances model fit and sparsity to achieve the desired performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df959d",
   "metadata": {},
   "source": [
    "__Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?__\n",
    "\n",
    "__Ans)__ Lasso Regression is primarily designed for linear regression problems, but it can be adapted for non-linear regression by incorporating non-linear transformations of the predictors. This involves applying non-linear functions, feature engineering, and selecting an appropriate regularization parameter. However, specialized non-linear regression techniques may be more suitable for complex non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fabb23",
   "metadata": {},
   "source": [
    "__Q6. What is the difference between Ridge Regression and Lasso Regression?__\n",
    "\n",
    "__Ans)__  Ridge Regression and Lasso Regression differ in the type of regularization used, the impact on coefficient estimates, and the ability to handle feature selection. Ridge Regression uses L2 regularization, shrinks coefficients towards zero, and maintains all predictors in the model. Lasso Regression uses L1 regularization, can set some coefficients to zero for feature selection, and produces a sparse model. Ridge Regression is suitable when all predictors may be relevant, while Lasso Regression is preferred when feature selection is desired or when some predictors are irrelevant. Elastic Net Regression combines both regularization types for a balanced approac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc774d9e",
   "metadata": {},
   "source": [
    "__Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?__\n",
    "\n",
    "__Ans)__  Lasso Regression can handle multicollinearity to some extent by performing feature selection and shrinking coefficients. It selects a subset of relevant predictors and eliminates some highly correlated predictors by setting their coefficients to zero. However, it may not completely resolve severe multicollinearity issues. In such cases, other regularization techniques like Ridge Regression or Elastic Net Regression may be more effective in addressing multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878817f",
   "metadata": {},
   "source": [
    "__Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?__\n",
    "\n",
    "__Ans)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4073a3",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------- __End__----------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
